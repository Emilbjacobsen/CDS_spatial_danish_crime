---
title: "North and South: Danish voters and Syrian refugees"
author: "Adela Sobotkova"
date: "19/03/2021 updated `r format(Sys.time(), '%B %d, %Y')`"
output:
  rmdformats::readthedown:
    highlight: kate
---


```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")
opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)
opts_knit$set(width=75)
```


```{r libraries, include=FALSE}
# Library 
library(raster)
library(rgeos)
library(sf)
library(tidyverse)
library(htmltools)
library(googlesheets4)
library(mapview)
```

# Task 1: Get spatial data for municipalities in Denmark 
You can download administrative data for Denmark from the GADM dataset, the Global administrative boundaries, hosted by UCDavis. You do this by using the getData() function in the `raster` package. For GADM data, you need to specify what level of admin boundaries you wish to download (0=country, 1=first level subdivision aka regions, 2=second level aka municipalities, etc.). Read [this blog](https://www.gis-blog.com/r-raster-data-acquisition/) on the power of `raster` package when it comes to available datasets. 

## Instructions:

* Use `getData()` function and `level = 2` to download the boundaries of Danish municipalities. 
* Note the class of the `mun_sp` object and the variable called `NAME_2`, it should be the name of the municipality
* Convert the `Spatial dataframe` to an sf object with `st_as_sf()` and project to Danish CRS (UTM32)
* Use `mapview` or `tmap` library to map all the municipalities.
* Sort the NAME_2 field to see how the Danish municipalities are spelled. You may need to change them later for the spatial data to join the attributes.

```{r load-spdata, eval = FALSE}

# Load the spatial data, project to UTM
mun_sp<- _______('GADM', country = 'DK', level = 2)
mun_sf <- ________(mun_sp)
mun <- st_transform(_____, crs = ____)

# Plot so as to check correct location and complete coverage


# Check the names


# Straighten the names (return here after Task 2)

```

```{r load-spdata, echo = FALSE}

# Load the spatial data, project to UTM
mun_sp<- getData('GADM', country = 'DK', level = 2)
mun_sf <- st_as_sf(mun_sp)
mun <- st_transform(mun_sf, crs = 25832)
st_crs(mun)

# Plot so as to check correct location and complete coverage
plot(mun$geometry)

# Check the names
mun$NAME_2

# Straighten the names (return here after Task 2)
mun$NAME_2[31] <- "Aarhus"
mun$NAME_2[21] <- "HÃ¸je-Taastrup"
mun$NAME_2[60] <- "Vesthimmerlands"
```


# Task 2: Wrangle the attributes and join to the spatial data
In order to show something we need to connect the spatial polygons with some attributes. Let's grab the election data table from Denmark Statistik and wrangle it so we can join it up with municipalities polygons and subject to adjacency analysis. 

Here we get to practice basic tidyverse/tidyr functions.

* Use `read_sheet()` function from `googlesheets4` package to load the prepared election data for 2011, 2015, and 2019
-   remember that `gs4_deauth()` can help if you have difficulty getting data from GDrive
* Check the municipality names, paying attention to Aarhus, Vesthimmerlands, etc. Is the spelling of municipality names and election region names the same between the table data and the spatial data you downloaded in Task 1 ?
* Find and fix the inconsistent names - learn how to programme your own R operator!
* Summarize the resulting data

```{r load-elec}
# Load the attributes
gs4_deauth()


elec <- read_sheet("https://docs.google.com/spreadsheets/d/1ty3UrUiCK2iqWVk2T2GORaCl0QZ6feUTMmTakXPVIIg/edit#gid=0", col_types = "ccnnn")
write_csv(elec, "data/elections.csv")

# Check names
sort(unique(elec$Region))

# Find inconsistencies
length(which(unique(elec$Region)%in%unique(mun$NAME_2)))

# Here is a little crutch to find and fix inconsistencies
'%nin%' <- Negate('%in%')
missing <- which(unique(elec$Region)%nin%unique(mun$NAME_2))
unique(elec$Region)[missing]

```


Now, after you have fixed the names of the municipalies, review the tabular data and then join it to the spatial data - transferring the data to polygons. Practicing data joining is extremely useful as no data is ever complete and most datasets in the world are relational. You are basically creating a relation now.  


* Summarize your data:
  - You need to know the total electorate in each municipality for 2011, 2015, and 2019 so create a summary dataset `electorate` with three new columns with summaries, eg. `sum2011`, `sum2015`,etc.
  
* Look up the  `merge` function to connect polygons with the raw `elec` and summary `electorate` datasets. 
  - You will need to find a column that the datasets share, so you can join them on the basis of this matching field, e.g. municipality name. It likely has a different column name in each dataset. Supply the specific column names in the `by` argument of the merge function. 
  
* Plot the merged results to make sure you have not lost any municipalities. If you have not make the municipality names consistent, some may not have a match and will be dropped.  `mapview()` is the best for interactive review 

* Once you have merged, summarize again:
  - You need summaries for each municipality by party turnout, ideally as a percentage of local electorate.
  - Group data by region and party and summarize it by each of the three years, adding three columns for 2011, 2015, and 2019, and calcuating the respective year turnout (for municipality and party) as a percentage of total electorate in that year (calculated earlier and merged into the data) which expresses what percentage of total voters in a given municipality, eg. `pct_vote2011`, `pct_vote2015`,...

* Plot the percentage of Social Democrat turnout in 2015 and 2011. Can you see the change?  
```{r summarize, echo = FALSE}
# Look at data and summarize
elec %>% 
  group_by(Party) %>% 
  summarize(sum2011 = sum(Y2011),
            sum2015 = sum(Y2015),
            sum2019 = sum(Y2019))  %>%
  janitor::adorn_totals(where = "row")

# Create total electorate per municipality
electorate <- elec %>% 
  group_by(Region) %>% 
  summarize(sum2011 = sum(Y2011),
            sum2015 = sum(Y2015),
            sum2019 = sum(Y2019)) 

# Merge the spatial polygons with the granular election dataset and the summary
elections <- mun %>% 
  select(NAME_2) %>% 
  merge(elec, by.x = "NAME_2",by.y ="Region") %>% 
  merge(electorate, by.x = "NAME_2",by.y ="Region") %>% 
  group_by(NAME_2, Party) %>% 
  mutate(pct_vote2011 = Y2011/sum2011*100,
         pct_vote2015 = Y2015/sum2015*100,
         pct_vote2019 = Y2019/sum2019*100)
elections

# Map some aspect of the result to see no counties are missing
elections %>% 
  group_by(NAME_2) %>% 
  filter(grepl("^A", Party)) %>%  # A.Socialdemokratie
  select(pct_vote2015) %>% 
  mapview()

# Save for later?
#write_rds(elections, "../data/elections_sp.rds") 
```


# Task 3: Look at some of the data

Now that we have a well-structured, complete and spatial dataset, let's explore the political preference distribution in space with the help of the lovely `tmap` library!

* Filter your elections data for Social Democrats and Danske Folkeparti (Hint: `grepl()` is a good start)
* then feed the result into `tm_shape()` and `tm_polygons`, faceting along the way by party. Since you have 2 parties, you should get two visuals.
* repeat three times, changing the `tm_polygons()` data from `pct_vote2011` to `pct_vote2019`
```{r map-data}
# Let's map the two most popular parties, SD and Danske Folkeparti through time
library(tmap)
elections %>% 
  filter(grepl("^A|^O",Party)) %>% 
  tm_shape() + 
  tm_facets("Party", ncol = 2) +
  tm_polygons("pct_vote2011",
              title= "Percentage of Votes \nin 2011")

elections %>% 
  filter(grepl("^A|^O",Party)) %>% 
  tm_shape() + 
  tm_facets("Party") +
  tm_polygons("pct_vote2015",
              title= "Percentage of Votes \nin 2015")

elections %>% 
  filter(grepl("^A|^O",Party)) %>% 
  tm_shape() + 
  tm_facets("Party") +
  tm_polygons("pct_vote2019",
              title= "Percentage of Votes \nin 2019")
```

# Task 4: Cartogram
As you can see from the maps, the area of municipalities varies considerably. When mapping them, the large areas carry more visual "weight" than small areas, although just as many people or more people live in the small areas. Voters in low-density rural regions can thus visually outweigh the urban hi-density populations.

One technique for correcting for this is the cartogram. This is a controlled distortion of the regions, expanding some and contracting others, so that the area of each region is proportional to a desired quantity, such as the population. The cartogram also tries to maintain the correct geography as much as possible, by keeping regions in roughly the same place relative to each other.

The `cartogram` package contains functions for creating cartograms. You give it a spatial data frame and the name of a column, and you get back a similar data frame but with regions distorted so that the region area is proportional to the column value of the regions.

You'll also use the sf package for computing the areas of newly generated regions with the `st_area()` function.

## Instructions

The `elections` sf object should be already loaded in your environment.

* Load the `cartogram` package.
* Filter out the Danske Folkeparti votes from your `elections` dataset, creating a `DF` object 
* Plot total electorate over municipality area for year 2015 in the `DF` data. Deviation from a straight line shows the degree of misrepresentation.
* Create a cartogram scaling to the `pct_vote2015` column.
* Check that the DF voter population is proportional to the area.
* Plot the `pct_vote2015` percentage on the cartogram. Notice how some areas have relatively shrunk or grown.

```{r cartogram-DF, eval=FALSE}
# Filter out Danske Folkeparti
DF <- elections %>% 
  filter(grepl("^O", Party))

# Make a cartogram, scaling the area to the percentage of SD voters
DF2015 <- cartogram_cont(DF, "pct_vote2015")

# Check the linearity of the SD voters percentage per municipality plot
plot(DF2015$pct_vote2015, st_area(DF2015, byid = TRUE))

```

Copacetic cartogram! Now try to rerun the cartogram for the Social Democrats in 2015 and create a visual for both parties' turnout and total electorate in 2015.

```{r carto-SD}
# Let's look at Social Democrats in 2015
DKSD <- elections %>% 
  filter(grepl("^A",Party)) 

# Make a cartogram, scaling the area to the total number of votes cast in 2015
SD2015 <- cartogram_cont(DKSD, "sum2015")

# Now check the linearity of the total voters per municipality cartogram as opposed to the reality
plot(DKSD$sum2015, st_area(DKSD , byid = TRUE)) # reality
plot(SD2015$sum2015, st_area(SD2015, byid = TRUE)) # cartogram


# Make a adjusted map of the 2015 SD and DF voters
plot(electorate2015$geometry, 
     col = "beige",
     main = "Electorate in DK municipalities 2015")
plot(SD2015$geometry,
     col="pink",
     main = "% of Social Democrat votes across DK in 2015")
plot(DF2015$geometry,
     col="lightblue",
     main = "% of Danske Folkeparti votes across DK in 2015")
```


# Task 5: Spatial autocorrelation test
If we look at the facetted tmaps the election results in 2015 seem to have spatial correlation - specifically the percentage of voters favoring Danske Folkeparti increases as you move towards the German border. This trend is not as visible in the cartogram, where the growth is more apparent in SjÃ¦land, and other islands, like SamsÃ¸. 

How much similarity and spatial dependence is there, really?

By similarity or positive correlation, we mean : pick any two kommunes that are neighbors - with a shared border - and their attributes will be more similar than any two random municipalities. 
Such autocorrelation or spatial dependence can be a problem when using statistical models that assume, conditional on the model, that the data points are independent.

The `spdep` package has functions for measures of spatial autocorrelation, also known as spatial dependency. Computing these measures first requires you to work out which regions are neighbors via the `poly2nb()` function, short for "polygons to neighbors". The result is an object of class `nb`. Then you can compute the test statistic and run a significance test on the null hypothesis of no spatial correlation. The significance test can either be done by Monte-Carlo or theoretical models.

In this example you'll use the Moran "I" statistic to test the spatial correlation of the Danske Folkeparti voters in 2015.

## Instructions I - defining neighbors

* Load the `elections` spatial dataset with attributes
* Consider simplifying the boundaries if the data is too heavy for your computer and takes long to visualise
* Load the spdep library and create nb object of neighbors using queen adjacency
* Pass `elections` to `poly2nb()` to find the neighbors of each municipality polygon. Assign to `nb`.
* Get the center points of each municipality by passing `elections` to `st_centroid` and then to `st_coordinates()`. Assign to `mun_centers`.
* Update the basic map of the DK municipalities by adding the connections.
  - In the second plot call pass `nb` and `mun_centers`.
  - Also pass `add = TRUE` to add to the existing plot rather than starting a new one.

```{r nb-contiguity}
# Reload the data if needed
# elections <- readRDS("data/elections_sp.rds")
elections
plot(elections$geometry)

# Consider simplifying (don't go too high)
mun_sm<- st_cast(st_simplify(mun, dTolerance = 250),
                     to = "MULTIPOLYGON")
plot(mun_sm$geometry)
length(st_is_valid(mun_sm$geometry))

# Use the spdep package
library(spdep)

# Make neighbor list following queen adjacency
nb <- poly2nb(mun_sm$geometry)
nb

# Get center points of each municipality
mun_centers <- st_coordinates(st_centroid(mun_sm$geometry))

# Show the connections
plot(mun_sm$geometry); plot(nb, mun_centers, col = "red",add = TRUE)
```


## Instructions II - Moran's I

Now that your neighbors are determined and centroids are computed, let's continuing with the Moran's I statistic

* Create a subset with municipalities for `O.Danske Folkeparti` 
* Feed the `pct_2011` vector into `moran.test()`.
  - `moran.test()` needs a weighted version of the `nb` object which you get by calling `nb2listw()`. 
  - After you specify your neighbor `nb`object (`mun_nb`) you should  define the weights `style = "W"`. Here, `style = "W"` indicates that the weights for each spatial unit are standardized to sum to 1 (this is known as row standardization). For example, municipality 1 has 3 neighbors, and each of those neighbors will have weights of 1/3.   This allows for comparability between areas with different numbers of neighbors.
  - You will need another argument in both spatial weights and at the level of the test. `zero.policy= TRUE` deals with situations when an area has no neighbors based on your definition of neighbor (many islands in Denmark). When this happens and you donât include `zero.policy= TRUE`, youâll get the following error
  - Run the test against the theoretical distribution of Moran's I statistic. Find the p-value. Can you reject the null hypothesis of no spatial correlation?
* Inspect a map of `pct_2011`.
* Run another Moran I statistic test, this time on Social Democrats.
  - Use 999 Monte-Carlo iterations via `moran.mc()`.
  - The first two arguments are the same as for `moran.test()`.
  - You also need to pass the argument `nsim = 999`.
  - Note the p-value. Can you reject the null hypothesis this time?
  


```{r Moran-DF-contig-sol, echo = FALSE}
# Let's look at Danske Folkeparti in 2015
DF <- elections %>% 
  filter(grepl("^O",Party))

# Run a Moran I test test on 2015 DF vote
moran.test(DF$pct_vote2015, 
           nb2listw(nb, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test test on 2011 DF vote
moran.test(DF$pct_vote2011, 
           nb2listw(nb, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Do a Monte Carlo simulation to get a better p-value
moran.mc(DF$pct_vote2015,nb2listw(nb, zero.policy=TRUE),zero.policy=TRUE, nsim = 999)
```

Marvellous Moran Testing! You should have found that the p-value was around 0.079 in 2015 and 0.15 in 2011 the first case, thus you did not find any significant spatial correlation. In Monte Carlo simulation, the p-value was around 0.053, so you did find some not very significant spatial correlation (strongly positive).

### Repeat the same test for Social Democrats
```{r Moran-SD}
# Let's look at Social Democrats
DKSD <- elections %>% 
  filter(grepl("^A",Party))

# Run a Moran I test on percentage of SD turnout in 2011
moran.test(DKSD$pct_vote2011, 
           nb2listw(nb, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test on percent of SD turnout in 2015
moran.test(DKSD$pct_vote2015, 
           nb2listw(nb, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Do a Monte Carlo simulation to get a better p-value
moran.mc(DKSD$pct_vote2011,nb2listw(nb, zero.policy=TRUE),zero.policy=TRUE, nsim = 999)

# Do a Monte Carlo simulation to get a better p-value
moran.mc(DKSD$pct_vote2015,nb2listw(nb, zero.policy=TRUE),zero.policy=TRUE, nsim = 999)
```

Phenomenal political testing. Social Democrats show even less correlation. P-value in Moran I test is was around 0.13 in 2011 results and 0.24 in 2015 results, thus no significant spatial correlation. In Monte Carlo simulation, the p-value was around 0.24, suggesting there is insignificant (positive) spatial correlation.


Well-done! Not so much correlation as it might seem at the first sight.

# Task 6: Different sorts of neighborhood: 50 km

## Connect the nearest places (islands)

```{r dnear-50}
# Reload the data if needed
mun

# Consider simplifying (don't go too high)
mun_sm<- st_cast(st_simplify(mun, dTolerance = 250),
                     to = "MULTIPOLYGON")
plot(mun_sm$geometry)

# Use the spdep package
library(spdep)

# Get center points of each municipality
mun_centers <-st_centroid(mun_sm$geometry, of_largest_polygon = TRUE)

# Make neighbor list from neighbours at 100km distance
nb_100 <- dnearneigh(mun_centers, 0, 100000)
plot(mun_sm$geometry); plot(nb_100, mun_centers, col = "red",add = TRUE)

# Make neighbor list from neighbours at 50km distance
nb_50 <- dnearneigh(mun_centers, 0, 50000)
plot(mun_sm$geometry); plot(nb_50, mun_centers, col = "blue",add = TRUE)
title(main="Neighbours within 50 km distance")
```

# Task 7: Different sorts of neighbourhood: k neighbors

```{r knear}
# Reload the data if needed
mun

# Consider simplifying (don't go too high)
mun_sm<- st_cast(st_simplify(mun, dTolerance = 250),
                     to = "MULTIPOLYGON")
plot(mun_sm$geometry)

# Use the spdep package
library(spdep)

# Get center points of each municipality
mun_centers <-st_centroid(mun_sm$geometry, of_largest_polygon = TRUE)

# Make neighbor list from neighbours at 100km distance
k3 <- knearneigh(mun_centers, k = 3)
nb_k3 <- knn2nb(knearneigh(mun_centers, k = 3))
plot(mun_sm$geometry); plot(nb_k3, mun_centers, col = "red",add = TRUE)
title(main="3 nearest neighbours")

# Make neighbor list from neighbours at 50km distance
nb_k5 <- knn2nb(knearneigh(mun_centers, k = 5))
plot(mun_sm$geometry); plot(nb_k5, mun_centers, col = "red",add = TRUE)
title(main="5 nearest neighbours")
```

# Taks 8: Rerun Moran's I
Now let's rerun Moran's I with different neighbour conceptions
```{r Moran-distance50, eval = FALSE}

# Run a Moran I test on Dansk Folkeparti votes in 2015 based on neighbors within 50km
moran.test(DF$_____,
           ________(_______, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test on Dansk Folkeparti votes in 2015 based on 3 neighbors
moran.test(DF$_____,
           ________(knn2nb(k3), style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test on Dansk Folkeparti votes in 2011 based on 3 neighbors
moran.test(DF$_____,
           ________(knn2nb(k3), style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Do a Monte Carlo simulation to get a better p-value
moran.mc(DF$___________,
         ________(knn2nb(k3), zero.policy=TRUE),
         zero.policy=TRUE, nsim = 999)

```

```{r Moran-distance50-sol, eval = FALSE}

# Run a Moran I test on Dansk Folkeparti votes in 2015 based on neighbors within 50km
moran.test(DF$pct_vote2015,
           nb2listw(nb_k3, style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test on Dansk Folkeparti votes in 2015 based on 3 neighbors
moran.test(DF$pct_vote2015,
           nb2listw(knn2nb(k3), style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Run a Moran I test on Dansk Folkeparti votes in 2011 based on 3 neighbors
moran.test(DF$pct_vote2011,
           nb2listw(knn2nb(k3), style = "W",zero.policy=TRUE),
           zero.policy=TRUE)

# Do a Monte Carlo simulation to get a better p-value
moran.mc(DF$pct_vote2011,
         nb2listw(knn2nb(k3), zero.policy=TRUE),
         zero.policy=TRUE, nsim = 999)
```